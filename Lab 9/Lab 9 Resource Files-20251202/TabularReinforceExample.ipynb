{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CE811 Tabular REINFORCE Example\n",
    "\n",
    "M. Fairbank, University of Essex\n",
    "\n",
    "- In this lab we use a table of action probabilities (one row for each cell of a maze) with the REINFORCE algorithm to solve a maze.\n",
    "\n",
    "- REINFORCE is a policy-gradient algorithm.  Unlike Q-learning, it requires completed trajectories (episodes) to work, so we force a trajectory-cutoff after 200 time steps.  \n",
    "\n",
    "- For this reason, we also require a smaller simpler maze to get this algorithm to work in a reasonable time.\n",
    "\n",
    "- In this notebook, there are just two \"TODO\" parts for you to complete.  Do these, and read through all of the code the code, run it, plot the graph; and try to understand it!\n",
    "\n",
    "Acknowledgements: This maze environment is based on one initially built by M. Pisheh (University of Essex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First build a maze environment (as in previous example):\n",
    "- The maze is simply a numpy array.  0s represent walkable areas.  1s represent solid walls.\n",
    "- The environment_step function is the function that executes an agent's action (i.e north/south/east/west) \n",
    "- It calculates the new state (y,x) and the instantaneous reward (-1 each step).\n",
    "- Note that throughout this notebook, states are y,x not x,y!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze [[1 1 1 1 1 1 1]\n",
      " [1 0 1 0 0 0 1]\n",
      " [1 0 1 1 1 0 1]\n",
      " [1 0 0 0 0 0 1]\n",
      " [1 1 1 0 1 0 1]\n",
      " [1 0 0 0 1 0 1]\n",
      " [1 1 1 1 1 1 1]]\n",
      "start [1, 1]\n",
      "goal [5, 5]\n"
     ]
    }
   ],
   "source": [
    "import random, os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "maze=np.array([\n",
    "        [1,1,1,1,1,1,1],\n",
    "        [1,0,1,0,0,0,1],\n",
    "        [1,0,1,1,1,0,1],\n",
    "        [1,0,0,0,0,0,1],\n",
    "        [1,1,1,0,1,0,1],\n",
    "        [1,0,0,0,1,0,1],\n",
    "        [1,1,1,1,1,1,1]])\n",
    "\n",
    "maze_width=maze.shape[1]\n",
    "maze_height=maze.shape[0]\n",
    "start_state = [1,1] # top left corner zero\n",
    "goal_state = [maze_height-2,maze_width-2] # bottom-right corner zero\n",
    "\n",
    "action_names=[\"North\",\"South\",\"West\",\"East\"]\n",
    "action_effects=[[-1,0],[1,0],[0,-1],[0,1]]\n",
    "\n",
    "def environment_step(action,state):\n",
    "    y,x = state\n",
    "    dy,dx=action_effects[action]\n",
    "    new_x = x+dx\n",
    "    new_y = y+dy\n",
    "    if new_x <0 or new_x>=maze_width:\n",
    "        # off grid\n",
    "        new_x = x\n",
    "    if new_y <0 or new_y>=maze_height:\n",
    "        # off grid\n",
    "        new_y = y\n",
    "    if maze[new_y,new_x] == 1:\n",
    "        # hit wall\n",
    "        new_y=y\n",
    "        new_x=x\n",
    "    new_state = [new_y,new_x]\n",
    "    reward = -1\n",
    "    done = (new_state==goal_state)\n",
    "    return new_state, reward, done\n",
    "\n",
    "print(\"maze\",maze)\n",
    "print(\"start\",start_state)\n",
    "print(\"goal\",goal_state)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next build our table of Probabilities for action in each maze cell. \n",
    "- There are 4 potential actions from each maze cell, therefore we need 4 probabilities for each maze cell.\n",
    "- Since the maze itself is shape [maze_height, maze_width], therefore we need an array of shape [maze_height, maze_width, 4]\n",
    "- Since in this table, every number is a completely free parameter, hence each row probably will not add up to 1 like probabilities do.  Hence we will need to remember to always use it in conjunction with softmax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 7, 4)\n"
     ]
    }
   ],
   "source": [
    "# Create our table of action probabilities.  We need 4 probabilities for every cell in the maze. \n",
    "table_action_probabilities_before_softmax=tf.Variable(np.zeros((maze_height,maze_width,len(action_names)),np.float32),tf.float32)\n",
    "print(table_action_probabilities_before_softmax.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next define a stochastic policy function\n",
    "- The policy gets probabilities directly from the table and the softmax function.\n",
    "- Once the 4 probabilities are known, it samples one of them at random.\n",
    "\n",
    "\n",
    "**TODO: Finish the *run_stochastic_policy* function below.**  \n",
    "- It needs to choose an action randomly, given the corresponding numpy array of probabilities.\n",
    "- So for example, if the array of probabilities is [0.1,0.3,0.2,0.4] then it needs to return 0 with probability 0.1, or return 1 with probability 0.3, or return 2 with probability 0.2, or return 3 with probability 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_probabilities(state):\n",
    "    y=state[0]\n",
    "    x=state[1]\n",
    "    # We can't just use a value straight from the table, because it might not be a valid probability between 0 and 1.\n",
    "    # Hence we still need to put all 4 probabilities through a softmax function to ensure they are all \n",
    "    # positive and sum to 1....\n",
    "    return tf.nn.softmax(table_action_probabilities_before_softmax[y,x,:])\n",
    "\n",
    "def run_stochastic_policy(current_state):\n",
    "    # Choose an action for current_state \n",
    "    probabilities=get_action_probabilities(current_state).numpy()# The .numpy() here converts from tensorflow tensor to a numpy array\n",
    "    action_chosen = np.random.choice(4,p=probabilities)# TODO write code here to set action_chosen to be 0,1,2 or 3, chosen randomly with probabilities gien by the probabilities array.\n",
    "    return action_chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test our stochastic policy is working reasonably well...\n",
    "\n",
    "- The following lines of code should roughly test our stochastic policy.  Run the code block below several times to check your epsilon greedy policy.\n",
    "- For a fuller test, run it through the auto-marker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This action should be chosen with uniform random chance: 0\n",
      "Run this code block several times to see if it is random\n"
     ]
    }
   ],
   "source": [
    "action_chosen=run_stochastic_policy([0,0])\n",
    "print(\"This action should be chosen with uniform random chance:\",action_chosen)\n",
    "print(\"Run this code block several times to see if it is random\")\n",
    "assert type(action_chosen) in [int,np.int64,np.int32], \"chosen_action is type \"+str(type(action_chosen))+\", which is not a simple integer type.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Define the REINFORCE update\n",
    "- Remember for REINFORCE, the update is $\\Delta \\theta=\\eta \\left(\\sum_t \\frac{dlog(P_t)}{d\\theta}\\right) (R-b)$ where $P_t$ is the probability assigned to the action that was actually chosen at time step $t$, (i.e. $P_t= p(a_t)$). We saw the proof in the lecture that $\\mathbb{E}(\\Delta \\theta)=\\eta \\frac{d\\mathbb{E}(R)}{d\\theta}$, i.e. that the expectation (average) of the REINFORCE update gives us gradient ascent on the expectation of total trajectory (episode) reward $R$.\n",
    "\n",
    "To work out $P_t$ for each trajectory step, we can use the following two lines of code:\n",
    "\n",
    "```\n",
    "trajectory_action_probabilities=get_action_probabilities_for_trajectory(trajectory) # this returns a tensor of shape [trajectory_length,4]\n",
    "chosen_probabilities=tf.gather(trajectory_action_probabilities, indices=action_choices, axis=1, batch_dims=1) # this returns a tensor of shape [trajectory_length]\n",
    "```\n",
    "\n",
    "This code is already given to you in the code block below.  When this code is run, it will create an array *chosen_probabilities* of shape [trajectory_length], and the array's content will be [$P_0$,$P_1$,...,$P_n$].  If you want more detail then see the help on [tf.gather](https://www.tensorflow.org/api_docs/python/tf/gather) to understand this more.\n",
    "\n",
    "- To compute the derivative used by REINFORCE, we will use auto-differentiation, because, remember our probabilities came from a softmax function,  and differentiating by hand through the softmax function might be beyond the scope of this course.  So we'll let TensorFlow do the hard work for us!...\n",
    "- To calculate $\\left(\\sum_t \\frac{dlog(P_t)}{d\\theta}\\right) (R-b)$, we will first simplify things a little, by writing,\n",
    "\\begin{align}&\\left(\\sum_t \\frac{dlog(P_t)}{d\\theta}\\right) (R-b)\\\\=&\\frac{d}{d\\theta}\\left[\\left(\\sum_t log(P_t)\\right)(R-b)\\right]\\\\\n",
    "=&\\frac{dL}{d\\theta}\\end{align}\n",
    "where we define:  \\begin{align}L=\\left(\\sum_t log(P_t)\\right)(R-b)\\end{align}\n",
    "- Now we can let TensorFlow just differentiate $L$, to obtain the gradient $\\frac{dL}{d\\theta}$.  This will enable us to do the weight update $\\Delta \\theta = \\eta \\frac{dL}{d\\theta}$.\n",
    "- Here $\\theta$ is our \"parameter vector\", by which we mean the learnable quantities.  So this is the variable *table_action_probabilities_before_softmax* in our case. \n",
    "- Hence we need to set up a gradient tape, and within it define $L=\\left(\\sum_t log(P_t)\\right)(R-b)$, and then use the gradient tape to compute $\\frac{dL}{d\\theta}$ for us, where $\\theta$ means table_action_probabilities_before_softmax.  You need to complete the following code to do that.  You will need to use the TensorFlow functions tf.math.log and tf.reduce_sum in here, and the multiplication and subtraction operations.  You will also need to use the variables chosen_probabilities, total_reward, and baseline.\n",
    "\n",
    "**TODO: finish the GradientTape code block below...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_probabilities_for_trajectory(trajectory):\n",
    "    # On entry, trajectory is a tensor of shape [trajectory_length,2]\n",
    "    # This returns a tensor of shape [trajectory_length,4]\n",
    "    # Each row of this tensor is an array of 4 probabilities applicable to timestep t\n",
    "    trajectory_length=len(trajectory)\n",
    "    # (These next 2 line could be made much more efficient by operating on whole trajectory at once!...)\n",
    "    trajectory_action_probabilities=[get_action_probabilities(trajectory[t,:]) for t in range(trajectory_length)]\n",
    "    return tf.stack(trajectory_action_probabilities) # converts the list to a tensor\n",
    "\n",
    "def calculate_reinforce_gradient(trajectory, total_reward, baseline, action_choices):\n",
    "    # This function is meant to calculate (dL/d Theta), where L=(\\sum_t (log(P_t))(R-b).\n",
    "    # You need to use the functions tf.math.log and tf.reduce_sum in here, plus the multiplication and subtraction operations.  \n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(table_action_probabilities_before_softmax)\n",
    "        trajectory_action_probabilities=get_action_probabilities_for_trajectory(trajectory) # this returns a tensor of shape [trajectory_length,4]\n",
    "        chosen_probabilities=tf.gather(trajectory_action_probabilities, indices=action_choices, axis=1, batch_dims=1) # this returns a tensor of shape [trajectory_length]\n",
    "        advantage=total_reward-baseline\n",
    "        log_probs=tf.math.log(chosen_probabilities)\n",
    "        L=tf.reduce_sum(log_probs)*advantage  # TODO fix this line of code!      \n",
    "    assert len(L.shape)==0 # checking the original large array has gone through a reduce_sum\n",
    "    grads = tape.gradient(L, table_action_probabilities_before_softmax) # This calculates the gradient required by REINFORCE\n",
    "    # This function doesn't actually do the update.  It just calculates the gradient ascent direction, and returns it!\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the main trajectory unroll loop, and learning algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 total_reward 0.05953855510552941 trajectory_length 56\n",
      "Iteration 1 total_reward 0.0033675975668514537 trajectory_length 112\n",
      "Iteration 2 total_reward 3.50526662488287e-05 trajectory_length 201\n",
      "Iteration 3 total_reward 0.048494525249423104 trajectory_length 60\n",
      "Iteration 4 total_reward 0.0007608599781118307 trajectory_length 141\n",
      "Iteration 5 total_reward 0.00027275759107716263 trajectory_length 161\n",
      "Iteration 6 total_reward 0.0010350542399058735 trajectory_length 135\n",
      "Iteration 7 total_reward 0.0030392568040834367 trajectory_length 114\n",
      "Iteration 8 total_reward 0.0003022244776478256 trajectory_length 159\n",
      "Iteration 9 total_reward 0.06944284018723361 trajectory_length 53\n",
      "Iteration 10 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 11 total_reward 0.0020163050597632507 trajectory_length 122\n",
      "Iteration 12 total_reward 3.50526662488287e-05 trajectory_length 201\n",
      "Iteration 13 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 14 total_reward 3.50526662488287e-05 trajectory_length 201\n",
      "Iteration 15 total_reward 0.06597069817787193 trajectory_length 54\n",
      "Iteration 16 total_reward 3.50526662488287e-05 trajectory_length 201\n",
      "Iteration 17 total_reward 0.012140317781059324 trajectory_length 87\n",
      "Iteration 18 total_reward 0.3405616262881148 trajectory_length 22\n",
      "Iteration 19 total_reward 0.002234133030208588 trajectory_length 120\n",
      "Iteration 20 total_reward 0.002234133030208588 trajectory_length 120\n",
      "Iteration 21 total_reward 0.051046868683603266 trajectory_length 59\n",
      "Iteration 22 total_reward 0.006905413874132088 trajectory_length 98\n",
      "Iteration 23 total_reward 0.022467088258818435 trajectory_length 75\n",
      "Iteration 24 total_reward 0.04157799358572413 trajectory_length 63\n",
      "Iteration 25 total_reward 0.12208654873684796 trajectory_length 42\n",
      "Iteration 26 total_reward 0.0016422930730837907 trajectory_length 126\n",
      "Iteration 27 total_reward 3.50526662488287e-05 trajectory_length 201\n",
      "Iteration 28 total_reward 0.00017190531077428803 trajectory_length 170\n",
      "Iteration 29 total_reward 0.02903546361765786 trajectory_length 70\n",
      "Iteration 30 total_reward 0.00847803669294384 trajectory_length 94\n",
      "Iteration 31 total_reward 0.19371148445850087 trajectory_length 33\n",
      "Iteration 32 total_reward 0.14989025404881545 trajectory_length 38\n",
      "Iteration 33 total_reward 0.18402591023557582 trajectory_length 34\n",
      "Iteration 34 total_reward 0.07694497527671315 trajectory_length 51\n",
      "Iteration 35 total_reward 0.030563645913324063 trajectory_length 69\n",
      "Iteration 36 total_reward 0.056561627350252934 trajectory_length 57\n",
      "Iteration 37 total_reward 0.04157799358572413 trajectory_length 63\n",
      "Iteration 38 total_reward 0.2039068257457904 trajectory_length 32\n",
      "Iteration 39 total_reward 0.19371148445850087 trajectory_length 33\n",
      "Iteration 40 total_reward 0.01829958380610923 trajectory_length 79\n",
      "Iteration 41 total_reward 0.22593554099256555 trajectory_length 30\n",
      "Iteration 42 total_reward 0.06597069817787193 trajectory_length 54\n",
      "Iteration 43 total_reward 0.043766309037604346 trajectory_length 62\n",
      "Iteration 44 total_reward 0.00507611374028386 trajectory_length 104\n",
      "Iteration 45 total_reward 0.323533544973709 trajectory_length 23\n",
      "Iteration 46 total_reward 3.50526662488287e-05 trajectory_length 201\n",
      "Iteration 47 total_reward 0.0059205292203339975 trajectory_length 101\n",
      "Iteration 48 total_reward 0.22593554099256555 trajectory_length 30\n",
      "Iteration 49 total_reward 0.14239574134637467 trajectory_length 39\n",
      "Iteration 50 total_reward 0.003544839544054162 trajectory_length 111\n",
      "Iteration 51 total_reward 0.26352009446574204 trajectory_length 27\n",
      "Iteration 52 total_reward 0.2039068257457904 trajectory_length 32\n",
      "Iteration 53 total_reward 0.03949909390643792 trajectory_length 64\n",
      "Iteration 54 total_reward 0.2503440897424549 trajectory_length 28\n",
      "Iteration 55 total_reward 0.001337657972358454 trajectory_length 130\n",
      "Iteration 56 total_reward 0.09944025698709225 trajectory_length 46\n",
      "Iteration 57 total_reward 0.12208654873684796 trajectory_length 42\n",
      "Iteration 58 total_reward 0.001408061023535215 trajectory_length 129\n",
      "Iteration 59 total_reward 0.048494525249423104 trajectory_length 60\n",
      "Iteration 60 total_reward 0.043766309037604346 trajectory_length 62\n",
      "Iteration 61 total_reward 0.06944284018723361 trajectory_length 53\n",
      "Iteration 62 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 63 total_reward 0.010408804957535737 trajectory_length 90\n",
      "Iteration 64 total_reward 0.3584859224085419 trajectory_length 21\n",
      "Iteration 65 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 66 total_reward 0.07309772651287749 trajectory_length 52\n",
      "Iteration 67 total_reward 0.12208654873684796 trajectory_length 42\n",
      "Iteration 68 total_reward 0.0809947108175928 trajectory_length 50\n",
      "Iteration 69 total_reward 0.06267216326897833 trajectory_length 55\n",
      "Iteration 70 total_reward 0.0006523423237336307 trajectory_length 144\n",
      "Iteration 71 total_reward 0.2503440897424549 trajectory_length 28\n",
      "Iteration 72 total_reward 0.07694497527671315 trajectory_length 51\n",
      "Iteration 73 total_reward 0.1577792147882268 trajectory_length 37\n",
      "Iteration 74 total_reward 0.2503440897424549 trajectory_length 28\n",
      "Iteration 75 total_reward 0.174824614723797 trajectory_length 35\n",
      "Iteration 76 total_reward 0.09944025698709225 trajectory_length 46\n",
      "Iteration 77 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 78 total_reward 0.19371148445850087 trajectory_length 33\n",
      "Iteration 79 total_reward 0.21463876394293727 trajectory_length 31\n",
      "Iteration 80 total_reward 0.27738957312183377 trajectory_length 26\n",
      "Iteration 81 total_reward 0.3073568677250236 trajectory_length 24\n",
      "Iteration 82 total_reward 0.3073568677250236 trajectory_length 24\n",
      "Iteration 83 total_reward 0.0852575903343082 trajectory_length 49\n",
      "Iteration 84 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 85 total_reward 0.10467395472325501 trajectory_length 45\n",
      "Iteration 86 total_reward 0.2919890243387724 trajectory_length 25\n",
      "Iteration 87 total_reward 0.01829958380610923 trajectory_length 79\n",
      "Iteration 88 total_reward 0.2919890243387724 trajectory_length 25\n",
      "Iteration 89 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 90 total_reward 0.12208654873684796 trajectory_length 42\n",
      "Iteration 91 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 92 total_reward 0.26352009446574204 trajectory_length 27\n",
      "Iteration 93 total_reward 0.053733545982740286 trajectory_length 58\n",
      "Iteration 94 total_reward 0.08974483193085075 trajectory_length 48\n",
      "Iteration 95 total_reward 0.3405616262881148 trajectory_length 22\n",
      "Iteration 96 total_reward 0.033865535638032206 trajectory_length 67\n",
      "Iteration 97 total_reward 0.048494525249423104 trajectory_length 60\n",
      "Iteration 98 total_reward 0.2503440897424549 trajectory_length 28\n",
      "Iteration 99 total_reward 0.12851215656510312 trajectory_length 41\n",
      "Iteration 100 total_reward 0.0852575903343082 trajectory_length 49\n",
      "Iteration 101 total_reward 0.3405616262881148 trajectory_length 22\n",
      "Iteration 102 total_reward 0.21463876394293727 trajectory_length 31\n",
      "Iteration 103 total_reward 0.020276547153583634 trajectory_length 77\n",
      "Iteration 104 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 105 total_reward 0.19371148445850087 trajectory_length 33\n",
      "Iteration 106 total_reward 0.11018311023500528 trajectory_length 44\n",
      "Iteration 107 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 108 total_reward 0.014159869113351015 trajectory_length 84\n",
      "Iteration 109 total_reward 0.07694497527671315 trajectory_length 51\n",
      "Iteration 110 total_reward 0.16608338398760716 trajectory_length 36\n",
      "Iteration 111 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 112 total_reward 0.3073568677250236 trajectory_length 24\n",
      "Iteration 113 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 114 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 115 total_reward 0.26352009446574204 trajectory_length 27\n",
      "Iteration 116 total_reward 0.051046868683603266 trajectory_length 59\n",
      "Iteration 117 total_reward 0.07694497527671315 trajectory_length 51\n",
      "Iteration 118 total_reward 0.2039068257457904 trajectory_length 32\n",
      "Iteration 119 total_reward 0.006905413874132088 trajectory_length 98\n",
      "Iteration 120 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 121 total_reward 0.3073568677250236 trajectory_length 24\n",
      "Iteration 122 total_reward 0.026204505914936217 trajectory_length 72\n",
      "Iteration 123 total_reward 0.10467395472325501 trajectory_length 45\n",
      "Iteration 124 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 125 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 126 total_reward 0.2919890243387724 trajectory_length 25\n",
      "Iteration 127 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 128 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 129 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 130 total_reward 0.2919890243387724 trajectory_length 25\n",
      "Iteration 131 total_reward 0.22593554099256555 trajectory_length 30\n",
      "Iteration 132 total_reward 0.2503440897424549 trajectory_length 28\n",
      "Iteration 133 total_reward 0.2919890243387724 trajectory_length 25\n",
      "Iteration 134 total_reward 0.3073568677250236 trajectory_length 24\n",
      "Iteration 135 total_reward 0.174824614723797 trajectory_length 35\n",
      "Iteration 136 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 137 total_reward 0.2919890243387724 trajectory_length 25\n",
      "Iteration 138 total_reward 0.27738957312183377 trajectory_length 26\n",
      "Iteration 139 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 140 total_reward 0.19371148445850087 trajectory_length 33\n",
      "Iteration 141 total_reward 0.1577792147882268 trajectory_length 37\n",
      "Iteration 142 total_reward 0.3405616262881148 trajectory_length 22\n",
      "Iteration 143 total_reward 0.006560143180425483 trajectory_length 99\n",
      "Iteration 144 total_reward 0.22593554099256555 trajectory_length 30\n",
      "Iteration 145 total_reward 0.3584859224085419 trajectory_length 21\n",
      "Iteration 146 total_reward 0.27738957312183377 trajectory_length 26\n",
      "Iteration 147 total_reward 0.27738957312183377 trajectory_length 26\n",
      "Iteration 148 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 149 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 150 total_reward 0.12208654873684796 trajectory_length 42\n",
      "Iteration 151 total_reward 0.3073568677250236 trajectory_length 24\n",
      "Iteration 152 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 153 total_reward 0.14239574134637467 trajectory_length 39\n",
      "Iteration 154 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 155 total_reward 0.23782688525533216 trajectory_length 29\n",
      "Iteration 156 total_reward 0.3584859224085419 trajectory_length 21\n",
      "Iteration 157 total_reward 0.04157799358572413 trajectory_length 63\n",
      "Iteration 158 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 159 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 160 total_reward 0.3073568677250236 trajectory_length 24\n",
      "Iteration 161 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 162 total_reward 0.22593554099256555 trajectory_length 30\n",
      "Iteration 163 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 164 total_reward 0.2919890243387724 trajectory_length 25\n",
      "Iteration 165 total_reward 0.26352009446574204 trajectory_length 27\n",
      "Iteration 166 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 167 total_reward 0.2919890243387724 trajectory_length 25\n",
      "Iteration 168 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 169 total_reward 0.2919890243387724 trajectory_length 25\n",
      "Iteration 170 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 171 total_reward 0.3584859224085419 trajectory_length 21\n",
      "Iteration 172 total_reward 0.1577792147882268 trajectory_length 37\n",
      "Iteration 173 total_reward 0.13527595427905592 trajectory_length 40\n",
      "Iteration 174 total_reward 0.323533544973709 trajectory_length 23\n",
      "Iteration 175 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 176 total_reward 0.2503440897424549 trajectory_length 28\n",
      "Iteration 177 total_reward 0.22593554099256555 trajectory_length 30\n",
      "Iteration 178 total_reward 0.174824614723797 trajectory_length 35\n",
      "Iteration 179 total_reward 0.2039068257457904 trajectory_length 32\n",
      "Iteration 180 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 181 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 182 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 183 total_reward 0.3584859224085419 trajectory_length 21\n",
      "Iteration 184 total_reward 0.26352009446574204 trajectory_length 27\n",
      "Iteration 185 total_reward 0.3073568677250236 trajectory_length 24\n",
      "Iteration 186 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 187 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 188 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 189 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 190 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 191 total_reward 0.26352009446574204 trajectory_length 27\n",
      "Iteration 192 total_reward 0.22593554099256555 trajectory_length 30\n",
      "Iteration 193 total_reward 0.23782688525533216 trajectory_length 29\n",
      "Iteration 194 total_reward 0.323533544973709 trajectory_length 23\n",
      "Iteration 195 total_reward 0.2039068257457904 trajectory_length 32\n",
      "Iteration 196 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 197 total_reward 0.12851215656510312 trajectory_length 41\n",
      "Iteration 198 total_reward 0.14989025404881545 trajectory_length 38\n",
      "Iteration 199 total_reward 0.2919890243387724 trajectory_length 25\n",
      "Iteration 200 total_reward 0.3405616262881148 trajectory_length 22\n",
      "Iteration 201 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 202 total_reward 0.22593554099256555 trajectory_length 30\n",
      "Iteration 203 total_reward 0.26352009446574204 trajectory_length 27\n",
      "Iteration 204 total_reward 0.048494525249423104 trajectory_length 60\n",
      "Iteration 205 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 206 total_reward 0.3405616262881148 trajectory_length 22\n",
      "Iteration 207 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 208 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 209 total_reward 0.017384604615803767 trajectory_length 80\n",
      "Iteration 210 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 211 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 212 total_reward 0.323533544973709 trajectory_length 23\n",
      "Iteration 213 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 214 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 215 total_reward 0.11598222130000556 trajectory_length 43\n",
      "Iteration 216 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 217 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 218 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 219 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 220 total_reward 0.14239574134637467 trajectory_length 39\n",
      "Iteration 221 total_reward 0.323533544973709 trajectory_length 23\n",
      "Iteration 222 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 223 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 224 total_reward 0.27738957312183377 trajectory_length 26\n",
      "Iteration 225 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 226 total_reward 0.27738957312183377 trajectory_length 26\n",
      "Iteration 227 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 228 total_reward 0.3405616262881148 trajectory_length 22\n",
      "Iteration 229 total_reward 0.2919890243387724 trajectory_length 25\n",
      "Iteration 230 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 231 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 232 total_reward 0.26352009446574204 trajectory_length 27\n",
      "Iteration 233 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 234 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 235 total_reward 0.26352009446574204 trajectory_length 27\n",
      "Iteration 236 total_reward 0.26352009446574204 trajectory_length 27\n",
      "Iteration 237 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 238 total_reward 0.3584859224085419 trajectory_length 21\n",
      "Iteration 239 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 240 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 241 total_reward 0.3405616262881148 trajectory_length 22\n",
      "Iteration 242 total_reward 0.05953855510552941 trajectory_length 56\n",
      "Iteration 243 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 244 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 245 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 246 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 247 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 248 total_reward 0.3405616262881148 trajectory_length 22\n",
      "Iteration 249 total_reward 0.11018311023500528 trajectory_length 44\n",
      "Iteration 250 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 251 total_reward 0.2503440897424549 trajectory_length 28\n",
      "Iteration 252 total_reward 0.3073568677250236 trajectory_length 24\n",
      "Iteration 253 total_reward 0.3584859224085419 trajectory_length 21\n",
      "Iteration 254 total_reward 0.27738957312183377 trajectory_length 26\n",
      "Iteration 255 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 256 total_reward 0.27738957312183377 trajectory_length 26\n",
      "Iteration 257 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 258 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 259 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 260 total_reward 0.3584859224085419 trajectory_length 21\n",
      "Iteration 261 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 262 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 263 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 264 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 265 total_reward 0.2919890243387724 trajectory_length 25\n",
      "Iteration 266 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 267 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 268 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 269 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 270 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 271 total_reward 0.3405616262881148 trajectory_length 22\n",
      "Iteration 272 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 273 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 274 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 275 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 276 total_reward 0.23782688525533216 trajectory_length 29\n",
      "Iteration 277 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 278 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 279 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 280 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 281 total_reward 0.323533544973709 trajectory_length 23\n",
      "Iteration 282 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 283 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 284 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 285 total_reward 0.26352009446574204 trajectory_length 27\n",
      "Iteration 286 total_reward 0.2503440897424549 trajectory_length 28\n",
      "Iteration 287 total_reward 0.3405616262881148 trajectory_length 22\n",
      "Iteration 288 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 289 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 290 total_reward 0.3584859224085419 trajectory_length 21\n",
      "Iteration 291 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 292 total_reward 0.27738957312183377 trajectory_length 26\n",
      "Iteration 293 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 294 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 295 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 296 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 297 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 298 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 299 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 300 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 301 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 302 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 303 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 304 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 305 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 306 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 307 total_reward 0.3405616262881148 trajectory_length 22\n",
      "Iteration 308 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 309 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 310 total_reward 0.22593554099256555 trajectory_length 30\n",
      "Iteration 311 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 312 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 313 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 314 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 315 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 316 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 317 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 318 total_reward 0.22593554099256555 trajectory_length 30\n",
      "Iteration 319 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 320 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 321 total_reward 0.3584859224085419 trajectory_length 21\n",
      "Iteration 322 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 323 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 324 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 325 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 326 total_reward 0.3073568677250236 trajectory_length 24\n",
      "Iteration 327 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 328 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 329 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 330 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 331 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 332 total_reward 0.3073568677250236 trajectory_length 24\n",
      "Iteration 333 total_reward 0.3073568677250236 trajectory_length 24\n",
      "Iteration 334 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 335 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 336 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 337 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 338 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 339 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 340 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 341 total_reward 0.3073568677250236 trajectory_length 24\n",
      "Iteration 342 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 343 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 344 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 345 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 346 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 347 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 348 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 349 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 350 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 351 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 352 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 353 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 354 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 355 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 356 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 357 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 358 total_reward 0.26352009446574204 trajectory_length 27\n",
      "Iteration 359 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 360 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 361 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 362 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 363 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 364 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 365 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 366 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 367 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 368 total_reward 0.3073568677250236 trajectory_length 24\n",
      "Iteration 369 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 370 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 371 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 372 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 373 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 374 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 375 total_reward 0.3584859224085419 trajectory_length 21\n",
      "Iteration 376 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 377 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 378 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 379 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 380 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 381 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 382 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 383 total_reward 0.2919890243387724 trajectory_length 25\n",
      "Iteration 384 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 385 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 386 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 387 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 388 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 389 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 390 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 391 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 392 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 393 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 394 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 395 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 396 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 397 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 398 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 399 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 400 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 401 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 402 total_reward 0.323533544973709 trajectory_length 23\n",
      "Iteration 403 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 404 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 405 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 406 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 407 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 408 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 409 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 410 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 411 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 412 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 413 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 414 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 415 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 416 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 417 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 418 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 419 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 420 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 421 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 422 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 423 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 424 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 425 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 426 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 427 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 428 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 429 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 430 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 431 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 432 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 433 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 434 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 435 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 436 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 437 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 438 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 439 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 440 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 441 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 442 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 443 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 444 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 445 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 446 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 447 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 448 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 449 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 450 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 451 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 452 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 453 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 454 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 455 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 456 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 457 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 458 total_reward 0.23782688525533216 trajectory_length 29\n",
      "Iteration 459 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 460 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 461 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 462 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 463 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 464 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 465 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 466 total_reward 0.2503440897424549 trajectory_length 28\n",
      "Iteration 467 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 468 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 469 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 470 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 471 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 472 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 473 total_reward 0.323533544973709 trajectory_length 23\n",
      "Iteration 474 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 475 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 476 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 477 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 478 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 479 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 480 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 481 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 482 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 483 total_reward 0.16608338398760716 trajectory_length 36\n",
      "Iteration 484 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 485 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 486 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 487 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 488 total_reward 0.3073568677250236 trajectory_length 24\n",
      "Iteration 489 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 490 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 491 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 492 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 493 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 494 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 495 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 496 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 497 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 498 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 499 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 500 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 501 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 502 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 503 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 504 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 505 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 506 total_reward 0.2919890243387724 trajectory_length 25\n",
      "Iteration 507 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 508 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 509 total_reward 0.3584859224085419 trajectory_length 21\n",
      "Iteration 510 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 511 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 512 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 513 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 514 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 515 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 516 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 517 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 518 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 519 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 520 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 521 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 522 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 523 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 524 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 525 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 526 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 527 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 528 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 529 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 530 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 531 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 532 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 533 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 534 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 535 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 536 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 537 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 538 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 539 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 540 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 541 total_reward 0.2919890243387724 trajectory_length 25\n",
      "Iteration 542 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 543 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 544 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 545 total_reward 0.3584859224085419 trajectory_length 21\n",
      "Iteration 546 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 547 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 548 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 549 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 550 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 551 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 552 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 553 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 554 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 555 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 556 total_reward 0.3972143184582182 trajectory_length 19\n",
      "Iteration 557 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 558 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 559 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 560 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 561 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 562 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 563 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 564 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 565 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 566 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 567 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 568 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 569 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 570 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 571 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 572 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 573 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 574 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 575 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 576 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 577 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 578 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 579 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 580 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 581 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 582 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 583 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 584 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 585 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 586 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 587 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 588 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 589 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 590 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 591 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 592 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 593 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 594 total_reward 0.2503440897424549 trajectory_length 28\n",
      "Iteration 595 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 596 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 597 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 598 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 599 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 600 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 601 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 602 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 603 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 604 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 605 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 606 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 607 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 608 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 609 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 610 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 611 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 612 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 613 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 614 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 615 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 616 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 617 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 618 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 619 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 620 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 621 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 622 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 623 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 624 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 625 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 626 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 627 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 628 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 629 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 630 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 631 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 632 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 633 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 634 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 635 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 636 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 637 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 638 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 639 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 640 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 641 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 642 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 643 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 644 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 645 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 646 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 647 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 648 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 649 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 650 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 651 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 652 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 653 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 654 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 655 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 656 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 657 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 658 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 659 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 660 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 661 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 662 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 663 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 664 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 665 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 666 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 667 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 668 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 669 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 670 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 671 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 672 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 673 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 674 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 675 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 676 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 677 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 678 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 679 total_reward 0.4181203352191771 trajectory_length 18\n",
      "Iteration 680 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 681 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 682 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 683 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 684 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 685 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 686 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 687 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 688 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 689 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 690 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 691 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 692 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 693 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 694 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 695 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 696 total_reward 0.21463876394293727 trajectory_length 31\n",
      "Iteration 697 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 698 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 699 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 700 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 701 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 702 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 703 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 704 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 705 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 706 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 707 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 708 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 709 total_reward 0.27738957312183377 trajectory_length 26\n",
      "Iteration 710 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 711 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 712 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 713 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 714 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 715 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 716 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 717 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 718 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 719 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 720 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 721 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 722 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 723 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 724 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 725 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 726 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 727 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 728 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 729 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 730 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 731 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 732 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 733 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 734 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 735 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 736 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 737 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 738 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 739 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 740 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 741 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 742 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 743 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 744 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 745 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 746 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 747 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 748 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 749 total_reward 0.44012666865176536 trajectory_length 17\n",
      "Iteration 750 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 751 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 752 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 753 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 754 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 755 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 756 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 757 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 758 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 759 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 760 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 761 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 762 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 763 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 764 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 765 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 766 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 767 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 768 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 769 total_reward 0.3584859224085419 trajectory_length 21\n",
      "Iteration 770 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 771 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 772 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 773 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 774 total_reward 0.37735360253530725 trajectory_length 20\n",
      "Iteration 775 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 776 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 777 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 778 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 779 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 780 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 781 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 782 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 783 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 784 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 785 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 786 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 787 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 788 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 789 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 790 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 791 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 792 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 793 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 794 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 795 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 796 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 797 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 798 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 799 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 800 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 801 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 802 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 803 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 804 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 805 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 806 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 807 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 808 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 809 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 810 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 811 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 812 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 813 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 814 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 815 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 816 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 817 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 818 total_reward 0.48767497911552954 trajectory_length 15\n",
      "Iteration 819 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 820 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 821 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 822 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 823 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 824 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 825 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 826 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 827 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 828 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 829 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 830 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 831 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 832 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 833 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 834 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 835 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 836 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 837 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 838 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 839 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 840 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 841 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 842 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 843 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 844 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 845 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 846 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 847 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 848 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 849 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 850 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 851 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 852 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 853 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 854 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 855 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 856 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 857 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 858 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 859 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 860 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 861 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 862 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 863 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 864 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 865 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 866 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 867 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 868 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 869 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 870 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 871 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 872 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 873 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 874 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 875 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 876 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 877 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 878 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 879 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 880 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 881 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 882 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 883 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 884 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 885 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 886 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 887 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 888 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 889 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 890 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 891 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 892 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 893 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 894 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 895 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 896 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 897 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 898 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 899 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 900 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 901 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 902 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 903 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 904 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 905 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 906 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 907 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 908 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 909 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 910 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 911 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 912 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 913 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 914 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 915 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 916 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 917 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 918 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 919 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 920 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 921 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 922 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 923 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 924 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 925 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 926 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 927 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 928 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 929 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 930 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 931 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 932 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 933 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 934 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 935 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 936 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 937 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 938 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 939 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 940 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 941 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 942 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 943 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 944 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 945 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 946 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 947 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 948 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 949 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 950 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 951 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 952 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 953 total_reward 0.46329123015975304 trajectory_length 16\n",
      "Iteration 954 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 955 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 956 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 957 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 958 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 959 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 960 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 961 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 962 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 963 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 964 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 965 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 966 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 967 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 968 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 969 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 970 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 971 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 972 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 973 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 974 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 975 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 976 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 977 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 978 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 979 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 980 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 981 total_reward 0.5403600876626367 trajectory_length 13\n",
      "Iteration 982 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 983 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 984 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 985 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 986 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 987 total_reward 0.5133420832795048 trajectory_length 14\n",
      "Iteration 988 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 989 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 990 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 991 total_reward 0.6302494097246091 trajectory_length 10\n",
      "Iteration 992 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 993 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 994 total_reward 0.6983372960937497 trajectory_length 8\n",
      "Iteration 995 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 996 total_reward 0.5987369392383787 trajectory_length 11\n",
      "Iteration 997 total_reward 0.6634204312890623 trajectory_length 9\n",
      "Iteration 998 total_reward 0.5688000922764597 trajectory_length 12\n",
      "Iteration 999 total_reward 0.6634204312890623 trajectory_length 9\n"
     ]
    }
   ],
   "source": [
    "iterations = 1000\n",
    "discount_factor=0.95\n",
    "reward_history=[]\n",
    "trajectory_length_history=[]\n",
    "\n",
    "optimizer=keras.optimizers.Adam(0.02)\n",
    "for iteration in range(iterations):\n",
    "    state=start_state\n",
    "    total_reward=0\n",
    "    done=False\n",
    "    time_step=0\n",
    "    trajectory=[]\n",
    "    step_rewards=[]\n",
    "    action_choices=[]\n",
    "    while not done:\n",
    "        action = run_stochastic_policy(state)\n",
    "        assert type(action) in [int,np.int64,np.int32], \"chosen_action is type \"+str(type(action))+\", which is not a simple integer type.\"\n",
    "        assert action>=0 and action<4\n",
    "        trajectory.append(np.array(state, np.int32))\n",
    "        #print(\"time_step\",time_step,\"state\",state,\"action\",action)\n",
    "        next_state, reward, done = environment_step(action, state)\n",
    "        step_rewards.append(reward)\n",
    "        action_choices.append(action)\n",
    "\n",
    "        state = next_state\n",
    "        time_step+=1\n",
    "        if time_step>200:\n",
    "            # break trajectory.  This maze is currently too difficult for REINFORCE to complete a trajectory.\n",
    "            done=True\n",
    "            \n",
    "    trajectory_length=time_step\n",
    "    #  The next line is a bit of a hack which speeds up learning a lot.\n",
    "    #  This is a much smoother reward function curve.  It is a function which gets higher the smaller \n",
    "    # the trajectory length is. See e.g. https://www.wolframalpha.com/input/?i=plot+y%3D0.95%5Ex+from+x%3D0+to+x%3D200 for the graph\n",
    "    total_reward=(discount_factor**(trajectory_length-1)) # This works pretty well\n",
    "\n",
    "    trajectory=np.stack(trajectory,axis=0) # np.stack converts a list into a numpy array of shape [trajectory_shape,2]\n",
    "    action_choices=np.stack(action_choices,axis=0) # np.stack converts a list into a numpy array of shape [trajectory_shape]\n",
    "    baseline=0\n",
    "    grads=calculate_reinforce_gradient(trajectory, total_reward, baseline, action_choices)\n",
    "    optimizer.apply_gradients(zip([-grads], [table_action_probabilities_before_softmax])) # This updates the parameter vector.  Note the minus sign here (because tensorflow optimize functions assume you only ever want graident DESCENT, but we want ascent here) \n",
    "    \n",
    "    trajectory_length_history.append(trajectory_length)\n",
    "    reward_history.append(total_reward)\n",
    "    print(\"Iteration\",iteration,\"total_reward\",total_reward, \"trajectory_length\",trajectory_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot graphs\n",
    "- Should show performance improving over time....\n",
    "- This maze is theoretically solvable in 8 steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(trajectory_length_history)\n",
    "plt.ylabel('Trajectory Length (Solution Time)')\n",
    "plt.xlabel('Iteration')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bit more theory (Optional section)\n",
    "\n",
    "When you see other people's implementations of REINFORCE, e.g. see Andrei Karpathy's [Pong from Pixels](http://karpathy.github.io/2016/05/31/rl/), they often use the cross-entropy error function.  This is because it turns out that cross-entropy loss function is very similar to what we need for REINFORCE (since they both have a log in them).\n",
    "\n",
    "Remember, the cross-entropy loss is defined to be:\n",
    "\\begin{align}\n",
    "L&=-\\sum_t log(P(y_t))\\\\\n",
    "\\end{align}\n",
    "where $P(y_t)$ means the probability that the neural network output gives to the true category $y_t$, and $t$ denotes the pattern index for each pattern in the training batch.\n",
    "\n",
    "With REINFORCE, in our code above, we did gradient ascent on $L$, where \\begin{align}\n",
    "L=(R-b) \\left[\\sum_t log(P(a_t))\\right]\\end{align}\n",
    "\n",
    "Hence the REINFORCE $L$ term looks almost the same as the Cross-Entropy loss.  They are the same, except that the REINFORCE expression has an extra multiplication by $-(R-b)$.  As most neural-network training libraries come with gradient calculators for Cross-Entropy, we can use that code to do REINFORCE updates.  The trick is to replace the \"true data label\" $y_t$ for each pattern number $t$, which the cross-entropy function receives, with the action which your policy chose, i.e. you just need to replace $y_t$ by $a_t$, where $a_t$ is the actual action your policy chose at time-step $t$.  \n",
    "\n",
    "So we should be able to replace the code we wrote for $L$ by $L=-(R-b)\\times$*cross_entropy(y_true=action_choices, y_pred=trajectory_action_probabilities)*, where *cross_entropy=tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.SUM)*.  If you want to try this in your submission to the auto-marker then do so.  Also, it means you can shorten the code quite a bit, and delete that awkward *tf.gather* line of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further experimentation ideas? (Optional section)\n",
    "\n",
    "- To get this method working on the larger maze (from the Q-learning example) we can use a discount factor = 0.98, and also use a baseline.  I found the baseline $b=0.98^{200}$ worked, as this meant that trajectories which fail don't cause any learning to happen.  Only the trajectories that solve the maze cause learning to happen (and they teach it how to solve the maze correctly, which is what we want!)\n",
    "\n",
    "To add more sophisticated functionality:\n",
    "\n",
    "- We could add a GUI to show the 4 probabilities for each maze cell changing over time.\n",
    "- We could try to set the baseline intelligently.  You could set it as the average reward obtained from the previous 20 trajectories, and update your baseline using this recipe after every new trajectory finishes.\n",
    "- We could employ \"exploring starts\", to try to be able to solve large mazes.  Instead of starting from location (1,1) each trajectory, we start from a random valid location in the maze.\n",
    "- We could add mini-batching - group together $N$ trajectories and find the average of their weight update, and apply that average all at once.  This should reduce the variance of the REINFORCE weight update, meaning we could use a higher learning rate.\n",
    "- We could try different reward functions, maybe one that uses a Euclidean heuristic for all failed trajectories.\n",
    "- You could try to learn a value function $\\widetilde{V}(s_t)$ for the state-value of each location in the maze $s_t$, (e.g. as a rolling average of the last 20 total trajectory rewards obtained after passing through that location), combined with exploring starts.  Then you could use this value function as the baseline for REINFORCE, i.e. use $\\Delta \\theta=\\eta \\left(\\sum_t \\frac{dlog(P_t)}{d\\theta}\\right) (R-\\widetilde{V}(s_t))$.   Hopefully we can get the learning performance to improve significantly like this.  You could then go a step further - why wait until the end of a very stochastic trajectory to have to evaluate $R$?  Why not replace the $R$ in the weight update by a value-function estimate of it, $R \\approx r_t+\\gamma \\widetilde{V}(s_{t+1})$, i.e. use the update $\\Delta \\theta=\\eta \\left(\\sum_t \\frac{dlog(P_t)}{d\\theta}\\right) (r_t+\\gamma \\widetilde{V}(s_{t+1})-\\widetilde{V}(s_t))$.  Doing this should lower the variance that was previously embedded into $R$ a lot, and hence speed up REINFORCE a lot. This should give you a good intuition as to what state value-functions are, and why they are useful. Note that this final form of update is the same as the \"Training the actor to be more greedy\" update which was given in the lecture on value functions.   (It sounds great, but then you have the problem of learning two interdependent things at once - a value function and a stochastic policy function.)\n",
    "- For the sake of improving your understanding, you could try replacing the automatic differentiation by a hand calculation of those derivatives?\n",
    "- You could replace the table of probabilities by a keras-model (neural network)\n",
    "\n",
    "\n",
    "If you take any of this further, for your own interest, then please email me with what you come up with!  m.fairbank@essex.ac.uk\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
